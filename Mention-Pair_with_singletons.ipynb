{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/weights/train_set2.csv\", delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1077826, 1191)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_features = len(data.values[0])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_features = data.values[:,0:number_of_features]\n",
    "labels = data.values[:,number_of_features] #last column consists of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_of_dataset = len(labels) #number of examples in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077826\n"
     ]
    }
   ],
   "source": [
    "print (size_of_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split data into trainig and validation set (99%/1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(999) #seed fixed for reproducibility\n",
    "mask = np.random.rand(size_of_dataset) < 0.99  #array of boolean variables\n",
    "\n",
    "training_set = input_features[mask]\n",
    "training_labels = labels[mask]\n",
    "\n",
    "validation_set = input_features[~mask]\n",
    "validation_labels = labels[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(number_of_features,))\n",
    "\n",
    "output_from_1st_layer = Dense(500)(inputs)\n",
    "output_from_1st_layer = BatchNormalization()(output_from_1st_layer)\n",
    "output_from_1st_layer = Activation('relu')(output_from_1st_layer)\n",
    "output_from_1st_layer = Dropout(0.2)(output_from_1st_layer)\n",
    "\n",
    "output_from_2nd_layer = Dense(200)(output_from_1st_layer)\n",
    "output_from_2nd_layer = BatchNormalization()(output_from_2nd_layer)\n",
    "output_from_2nd_layer = Activation('relu')(output_from_2nd_layer)\n",
    "output_from_2nd_layer = Dropout(0.2)(output_from_2nd_layer)\n",
    "\n",
    "\n",
    "output_from_3rd_layer = Dense(100)(output_from_2nd_layer)\n",
    "output_from_3rd_layer = BatchNormalization()(output_from_3rd_layer)\n",
    "output_from_3rd_layer = Activation('relu')(output_from_3rd_layer)\n",
    "output_from_3rd_layer = Dropout(0.2)(output_from_3rd_layer)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(output_from_3rd_layer)\n",
    "\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model compilation with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(labels), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.62377511  2.51979221]\n"
     ]
    }
   ],
   "source": [
    "print (class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1077826/1077826 [==============================] - 111s - loss: 0.2477 - acc: 0.8926   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72e3ffc8d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_features, labels, batch_size=128, epochs=1, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"model_with_singletons.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/weights/test_set.csv\", delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = test_data.values[:,0:number_of_features]\n",
    "test_labels = test_data.values[:,number_of_features] #last column consists of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20253\n",
      "20424\n"
     ]
    }
   ],
   "source": [
    "mask = test_labels < 1\n",
    "negative_examples = test_set[mask]\n",
    "negative_labels = test_labels[mask]\n",
    "\n",
    "mask_2 = np.random.rand(len(negative_labels)) < 0.2  #array of boolean variables\n",
    "negative_examples = negative_examples[mask_2]\n",
    "negative_labels = negative_labels[mask_2]\n",
    "\n",
    "positive_examples = test_set[~mask]\n",
    "positive_labels = test_labels[~mask]\n",
    "\n",
    "print (len(negative_examples))\n",
    "print (len(positive_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = np.concatenate((positive_examples, negative_examples), axis=0)\n",
    "test_labels = np.concatenate((positive_labels, negative_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40416/40677 [============================>.] - ETA: 0sPrecision: 0.880%\n",
      "Recall: 0.851%\n",
      "Accuracy: 0.867%\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_set, verbose=1)\n",
    "\n",
    "threshold = 0.20\n",
    "true_positives = 0.0\n",
    "false_negatives = 0.0\n",
    "false_positives = 0.0\n",
    "true_negatives = 0.0\n",
    "total = len(pred) \n",
    "\n",
    "for i in range(0,len(pred)):\n",
    "    if (test_labels[i]==1 and pred[i]>threshold):\n",
    "        true_positives+=1\n",
    "    if (test_labels[i]==1 and pred[i]<=threshold):\n",
    "        false_negatives+=1\n",
    "    if (test_labels[i]==0 and pred[i]>threshold):\n",
    "        false_positives+=1\n",
    "    if (test_labels[i]==0 and pred[i]<=threshold):\n",
    "        true_negatives+=1     \n",
    "        \n",
    "print('Precision: %0.3f%%' % (true_positives/(true_positives+false_positives))) \n",
    "print('Recall: %0.3f%%' % (true_positives/(true_positives+false_negatives)))\n",
    "print('Accuracy: %0.3f%%' % ((true_positives+true_negatives)/(total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"model_with_singletons.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and generate prediction for a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98887503\n"
     ]
    }
   ],
   "source": [
    "single_example = test_set[4:5,:] #example number 5 from the test set\n",
    "prediction = model.predict(single_example)\n",
    "print ('%.8f' % prediction[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
